{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading _not quantized_ ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "###### AE MODEL LOAD ######\n",
    "ae_wo_classifier = load_model('model/AE_model/KERAS_check_best_model.h5')\n",
    "# ae_wo_classifier_pruned = load_model('model/AE_model/KERAS_check_pruned_best_model.h5')\n",
    "ae_wo_classifier_pruned = load_model('model/AE_model/KERAS_check_pruned_best_model.model')\n",
    "ae_w_classifier = load_model('model/AE_model/KERAS_check_best_model_classifier.h5')\n",
    "ae_w_classifier_pruned = load_model('model/AE_model/KERAS_check_pruned_best_model_classifier.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading _quantized_ ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from qkeras.utils import _add_supported_quantized_objects\n",
    "co = {}\n",
    "_add_supported_quantized_objects(co)\n",
    "###### QAE MODEL LOAD ######\n",
    "\n",
    "#qae_wo_classifier = load_model('model/QAE_model/KERAS_check_best_model.h5', custom_objects=co)\n",
    "qae_wo_classifier_pruned = load_model('model/QAE_model/KERAS_check_pruned_best_model.h5', custom_objects=co)\n",
    "#qae_w_classifier = load_model('model/QAE_model/KERAS_check_best_model_classifier.h5', custom_objects=co)\n",
    "\n",
    "#qae_w_classifier_pruned = load_model('model/QAE_model/KERAS_check_pruned_best_model_only_classifier.h5', custom_objects=co)\n",
    "qae_w_classifier_pruned = load_model('model/QAE_model/KERAS_check_pruned_best_model_classifier1.h5', custom_objects=co)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check sparsity\n",
    "Make a quick check that the model was indeed trained sparse. We'll just make a histogram of the weights of the 1st layer, and hopefully observe a large peak in the bin containing '0'. Note logarithmic y axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum = 0\n",
    "sum_pru = 0\n",
    "\n",
    "for i in [2,3,5]:\n",
    "    for j in [0,1]:\n",
    "        w= ae_w_classifier.layers[i].weights[j].numpy()\n",
    "        sum +=w.size \n",
    "        w_prun = ae_w_classifier_pruned.layers[i].weights[j].numpy()\n",
    "        sum_pru += w.size - np.sum(w_prun==0)\n",
    "\n",
    "        if j==0:\n",
    "            print('weights:')\n",
    "        else:\n",
    "            print('bias:')\n",
    "        \n",
    "        print(w.size,'\\n', w.size - np.sum(w_prun==0))\n",
    "\n",
    "    print(\"layer\"+str(i),'\\n')\n",
    "print (sum, '\\n',  sum -sum_pru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "w = 10\n",
    "h = 10\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "columns = 2\n",
    "rows = 4\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "num_layers = [1,2,3,4,7,9,11]#,11,14,15]\n",
    "#this applies for the quantized loop\n",
    "num_layers = [1,3,5,7,8,10,12]#,11,14,15]\n",
    "\n",
    "\n",
    "j = 1\n",
    "\n",
    "for i in num_layers:\n",
    "#for i in range(1, columns*rows +1):  \n",
    "    fig.add_subplot(rows, columns, j)\n",
    "    w = qae_w_classifier_pruned.layers[i].weights[0].numpy()\n",
    "    h, b = np.histogram(w, bins=100)\n",
    "    plt.bar(b[:-1], h, width=b[1]-b[0])\n",
    "    plt.semilogy()\n",
    "    plt.title('Weight distribution of layer '+ str(j))\n",
    "    j += 1\n",
    "\n",
    "plt.savefig('./Report/images/section4/ae_pruned_weightsdistr.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make an hls4ml config & model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotting\n",
    "import hls4ml\n",
    "hls4ml.model.optimizer.OutputRoundingSaturationMode.layers = ['Activation']\n",
    "hls4ml.model.optimizer.OutputRoundingSaturationMode.rounding_mode = 'AP_RND'\n",
    "hls4ml.model.optimizer.OutputRoundingSaturationMode.saturation_mode = 'AP_SAT'\n",
    "\n",
    "config = hls4ml.utils.config_from_keras_model(qae_w_classifier_pruned, granularity='name')\n",
    "config['LayerName']['encoder_input']['Precision']='ap_ufixed<6,0>'\n",
    "\n",
    "#config['LayerName']['classifier_output']['Precision'] = 'ap_fixed<32,12>'\n",
    "config['LayerName']['classifier_output']['exp_table_t'] = 'ap_fixed<18,8>'\n",
    "config['LayerName']['classifier_output']['inv_table_t'] = 'ap_fixed<18,4>'\n",
    "print(\"-----------------------------------\")\n",
    "plotting.print_dict(config)\n",
    "print(\"-----------------------------------\")\n",
    "hls_model = hls4ml.converters.convert_from_keras_model(qae_w_classifier_pruned,\n",
    "                                                       hls_config=config,\n",
    "                                                       output_dir='model/QAE_model/hls4ml_prj',\n",
    "                                                       part='xcu250-figd2104-2L-e')\n",
    "                                                       #part='xcvu9p-flgc2104aaz')\n",
    "                                                       #part='xc7vx690t-ffg176-2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_model.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_model.build(csim=True, cosim=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MNIST_database as mnist\n",
    "\n",
    "#Choose the final size of your image dataset\n",
    "size_final = 8\n",
    "\n",
    "data_zoom = mnist.MNISTData(size_initial=20, size_final=size_final, color_depth=5, flat=True)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#           0  1  2  3  4  5  6  7  8  9          \n",
    "num_list = [3, 2, 1, 32,4, 15,21,0, 61,12] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = np.flip(data_zoom.x_test[num_list[3]].reshape(1,-1))\n",
    "#img = data_zoom.x_test[32].reshape(1,-1)\n",
    "#plt.imshow(img.reshape(size_final,size_final), cmap='gray_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = []\n",
    "ax = plt.subplot(1, 1 , 1)\n",
    "img = data_zoom.x_test[num_list[0]].reshape(1,-1)\n",
    "\n",
    "plt.imshow(img.reshape(size_final,size_final), cmap='gray_r')\n",
    "print(img)\n",
    "plt.imshow(img.reshape(size_final,size_final), cmap='gray_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "img = data_zoom.x_test[num_list[1]].reshape(1,-1)\n",
    "plt.imshow(img.reshape(size_final,size_final), cmap='gray_r')\n",
    "start_time = time.time()\n",
    "out = qae_w_classifier_pruned.predict(img)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(out)\n",
    "print(np.sum(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = hls_model.predict(img)[1]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "d1b75f63a51ab1e44c10e89cf3b718812d9c5e2447d39cb402b946ba7653bfcd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
